{"componentChunkName":"component---src-templates-post-template-js","path":"/llms-and-quarkus-techxchange/","result":{"data":{"post":{"id":"78b855cb-9960-5cb4-8559-024a8a04d583","html":"<p>Generative AI has taken the world by storm over the last year, and it seems like every executive leader out there is telling us “regular” Java application developers to “add AI” to our applications. Does that mean we need to drop everything we’ve built and become data scientists instead now? Fortunately, we can actually infuse AI models built by actual AI experts into our applications fairly straightforwardly, thanks to some new projects out there. We promise it’s not as complicated as you might think! Thanks to the ease of use and superb developer experience of Quarkus and the nice AI integration capabilities that the LangChain4j libraries offer, it becomes trivial to start working with AI and make your stakeholders happy :) In this session, you’ll explore a variety of AI capabilities. We’ll start from the Quarkus DevUI where you can try out AI models even before writing any code. Then we’ll get our hands dirty with some code and exploring LangChain4j features such as prompting, chaining, and preserving state; agents and function-calling; enriching your AI model’s knowledge with your own documents using retrieval augmented generation (RAG); and discovering ways to run (and train) models locally using tools like Ollama and/or Podman AI Lab. In addition, we’ll take a look at observability and fault tolerance of the AI integration and compile the app to a native binary.</p>","excerpt":"Generative AI has taken the world by storm over the last year, and it seems like every executive leader out there is telling us “regular…","fields":{"title":"The Power of LLMs in Java – Leveraging Quarkus and LangChain4j","slug":"/llms-and-quarkus-techxchange/","prefix":"2024-10-23","shortDate":"10-23","category":"ai","author":"holly cummins","displayCategory":"ai","geography":{"flag":"PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA1MTMgMzQyIj48cGF0aCBmaWxsPSIjRkZGIiBkPSJNMCAwaDUxM3YzNDJIMHoiLz48ZyBmaWxsPSIjRDgwMDI3Ij48cGF0aCBkPSJNMCAwaDUxM3YyNi4zSDB6TTAgNTIuNmg1MTN2MjYuM0gwek0wIDEwNS4yaDUxM3YyNi4zSDB6TTAgMTU3LjhoNTEzdjI2LjNIMHpNMCAyMTAuNWg1MTN2MjYuM0gwek0wIDI2My4xaDUxM3YyNi4zSDB6TTAgMzE1LjdoNTEzVjM0MkgweiIvPjwvZz48cGF0aCBmaWxsPSIjMkU1MkIyIiBkPSJNMCAwaDI1Ni41djE4NC4xSDB6Ii8+PGcgZmlsbD0iI0ZGRiI+PHBhdGggZD0ibTQ3LjggMTM4LjktNC0xMi44LTQuNCAxMi44SDI2LjJsMTAuNyA3LjctNCAxMi44IDEwLjktNy45IDEwLjYgNy45LTQuMS0xMi44IDEwLjktNy43ek0xMDQuMSAxMzguOWwtNC4xLTEyLjgtNC4yIDEyLjhIODIuNmwxMC43IDcuNy00IDEyLjggMTAuNy03LjkgMTAuOCA3LjktNC0xMi44IDEwLjctNy43ek0xNjAuNiAxMzguOWwtNC4zLTEyLjgtNCAxMi44aC0xMy41bDExIDcuNy00LjIgMTIuOCAxMC43LTcuOSAxMSA3LjktNC4yLTEyLjggMTAuNy03Ljd6TTIxNi44IDEzOC45bC00LTEyLjgtNC4yIDEyLjhoLTEzLjNsMTAuOCA3LjctNCAxMi44IDEwLjctNy45IDEwLjggNy45LTQuMy0xMi44IDExLTcuN3pNMTAwIDc1LjNsLTQuMiAxMi44SDgyLjZMOTMuMyA5NmwtNCAxMi42IDEwLjctNy44IDEwLjggNy44LTQtMTIuNiAxMC43LTcuOWgtMTMuNHpNNDMuOCA3NS4zbC00LjQgMTIuOEgyNi4yTDM2LjkgOTZsLTQgMTIuNiAxMC45LTcuOCAxMC42IDcuOEw1MC4zIDk2bDEwLjktNy45SDQ3Ljh6TTE1Ni4zIDc1LjNsLTQgMTIuOGgtMTMuNWwxMSA3LjktNC4yIDEyLjYgMTAuNy03LjggMTEgNy44LTQuMi0xMi42IDEwLjctNy45aC0xMy4yek0yMTIuOCA3NS4zbC00LjIgMTIuOGgtMTMuM2wxMC44IDcuOS00IDEyLjYgMTAuNy03LjggMTAuOCA3LjgtNC4zLTEyLjYgMTEtNy45aC0xMy41ek00My44IDI0LjdsLTQuNCAxMi42SDI2LjJsMTAuNyA3LjktNCAxMi43TDQzLjggNTBsMTAuNiA3LjktNC4xLTEyLjcgMTAuOS03LjlINDcuOHpNMTAwIDI0LjdsLTQuMiAxMi42SDgyLjZsMTAuNyA3LjktNCAxMi43TDEwMCA1MGwxMC44IDcuOS00LTEyLjcgMTAuNy03LjloLTEzLjR6TTE1Ni4zIDI0LjdsLTQgMTIuNmgtMTMuNWwxMSA3LjktNC4yIDEyLjcgMTAuNy03LjkgMTEgNy45LTQuMi0xMi43IDEwLjctNy45aC0xMy4yek0yMTIuOCAyNC43bC00LjIgMTIuNmgtMTMuM2wxMC44IDcuOS00IDEyLjcgMTAuNy03LjkgMTAuOCA3LjktNC4zLTEyLjcgMTEtNy45aC0xMy41eiIvPjwvZz48L3N2Zz4=","country":"United States"},"video":null,"slides":null,"oembeds":null,"cover":{"childImageSharp":{"resize":{"src":"/static/89698dfadf0bb3c133af681004f13991/630fb/placeholder.png"}}}},"frontmatter":{"type":"talk","event":"IBM TechXchange","keynote":null,"code":null,"resources":null}},"authornote":{"id":"77e0dd69-1df1-59df-9a8e-f3f29c267627","html":"<p><strong>Holly Cummins</strong>. Holly Cummins is a Senior Principal Software Engineer at Red Hat, in the Quarkus Team. She is a\nkeynote speaker, author, and bad illustrator.</p>"}},"pageContext":{"slug":"/llms-and-quarkus-techxchange/","prev":{"id":"27823eae-84a2-52b1-a9ae-3921c2e95120","fields":{"slug":"/java-runtimes-techxchange/","prefix":"2024-10-22","draft":null,"source":"talks","category":"quarkus"},"frontmatter":{"title":"Choosing the right Java runtime for the job","url":null,"type":"talk"}},"next":{"id":"0279d9bc-2dc3-56f6-a756-c6cfac3e425a","fields":{"slug":"/quarkus-techxchange/","prefix":"2024-10-23","draft":null,"source":"talks","category":"quarkus"},"frontmatter":{"title":"Refactoring to Kube-native Java with Quarkus","url":null,"type":"talk"}},"source":"talks"}},"staticQueryHashes":["1862184931","2262979903","421231837"],"slicesMap":{}}